{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7v4gjWdZb9P7"
      },
      "outputs": [],
      "source": [
        "# Install the OpenAI library quietly (without output)\n",
        "!pip install -q openai\n",
        "\n",
        "# Import necessary libraries\n",
        "import openai  # For accessing OpenAI's APIs\n",
        "import os      # For managing environment variables\n",
        "import pandas as pd  # For handling data in tabular format\n",
        "\n",
        "# Set the OpenAI API key securely using environment variables (recommended over hardcoding)\n",
        "os.environ['OPENAI_API_KEY'] = 'sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\n",
        "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "# Load the unicorn startup dataset into a DataFrame\n",
        "df = pd.read_csv(\"unicorns.csv\")\n",
        "\n",
        "# Display the column names in the dataset\n",
        "print(df.columns)\n",
        "\n",
        "# Show the first 5 rows to get a quick overview\n",
        "print(df.head())\n",
        "\n",
        "# Display detailed info about the dataset: column types, null values, memory usage, etc.\n",
        "print(df.info())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast  # For safely evaluating string representations of Python data structures\n",
        "\n",
        "# Function to generate a summary text for each company based on its metadata\n",
        "def summary(company, crunchbase_url, city, country, industry, investor_list):\n",
        "    investors = \"The investors in the company are \"\n",
        "\n",
        "    # Convert the stringified list of investors back to a Python list\n",
        "    for investor in ast.literal_eval(investor_list):\n",
        "        investors += f\"{investor},\"\n",
        "\n",
        "    # Build a full descriptive sentence about the company\n",
        "    text = (\n",
        "        f\"{company} has headquarters in {city} in {country} and is in the field of {industry}. \"\n",
        "        f\"{investors}. More info at {crunchbase_url}\"\n",
        "    )\n",
        "    return text\n",
        "\n",
        "# Apply the summary function to each row in the DataFrame and create a new 'summary' column\n",
        "df['summary'] = df.apply(lambda row: summary(\n",
        "    row['Company'], row['Crunchbase Url'], row['City'],\n",
        "    row['Country'], row['Industry'], row['Investors']), axis=1)\n",
        "\n",
        "# Optional: Display one summary nicely formatted to 100-character width\n",
        "import textwrap\n",
        "text = df['summary'][1]\n",
        "wrapped_text = textwrap.fill(text, width=100)\n",
        "print(wrapped_text)\n"
      ],
      "metadata": {
        "id": "b1C7V3o4ckwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the tiktoken library (used for token counting, compatible with OpenAI models)\n",
        "!pip install tiktoken\n",
        "\n",
        "import tiktoken  # Tokenizer library for OpenAI models\n",
        "\n",
        "# Function to count the number of tokens in a string using a specified encoding\n",
        "def num_tokens_from_string(string, encoding_name=\"cl100k_base\"):\n",
        "    encoding = tiktoken.get_encoding(encoding_name)\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens\n",
        "\n",
        "# Calculate the number of tokens for each summary and store it in a new column\n",
        "df[\"token_count\"] = df['summary'].apply(num_tokens_from_string)\n",
        "\n",
        "# Estimate the total number of tokens and cost (based on $0.0001 per 1,000 tokens)\n",
        "total_tokens = int(df[\"token_count\"].sum())\n",
        "cost = float(total_tokens * 0.0001 / 1000)\n",
        "\n",
        "# Print total token count and estimated embedding cost\n",
        "print(f\"Total tokens: {total_tokens}, Estimated cost: ${cost:.4f}\")\n"
      ],
      "metadata": {
        "id": "_wItxXs6cpfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get an embedding vector for a given text using OpenAI's embedding model\n",
        "def get_embedding(text):\n",
        "    response = openai.embeddings.create(\n",
        "        input=text,\n",
        "        model='text-embedding-ada-002'  # Efficient and low-cost embedding model\n",
        "    )\n",
        "    return response.data[0].embedding  # Return the embedding vector from the response\n",
        "\n",
        "# Apply the embedding function to each summary and store the result in a new column\n",
        "df['embedding'] = df['summary'].apply(get_embedding)\n",
        "\n",
        "# Save the updated DataFrame with embeddings to a new CSV file\n",
        "df.to_csv('my_embedding.csv', index=False)\n"
      ],
      "metadata": {
        "id": "KyGPbPvkcrfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity  # For measuring similarity between vectors\n",
        "\n",
        "# Function to compute cosine similarity between two vectors\n",
        "def vector_similarity(vec1, vec2):\n",
        "    return cosine_similarity([vec1], [vec2])[0][0]\n",
        "\n",
        "# Example user query\n",
        "prompt = \"What does the company Minio do and where is the HQ?\"\n",
        "\n",
        "# Generate the embedding vector for the user query\n",
        "prompt_embedding = get_embedding(prompt)\n",
        "\n",
        "# Compute similarity between the query embedding and each company's embedding in the DataFrame\n",
        "df['prompt_similarity'] = df['embedding'].apply(lambda vector: vector_similarity(vector, prompt_embedding))\n",
        "\n",
        "# Find the company with the highest similarity score to the query\n",
        "most_similar = df.nlargest(1, 'prompt_similarity').iloc[0]\n",
        "\n",
        "# Print the summary of the most relevant company\n",
        "print(most_similar['summary'])\n"
      ],
      "metadata": {
        "id": "akw8CQryctLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the context and question prompt for the chat completion model\n",
        "context = most_similar['summary']\n",
        "\n",
        "follow_up_prompt = f'''Only answer the question below if you have 100% certainty of the facts.\n",
        "Context: {context}\n",
        "Q: What does the start-up company Pentera do and who invested in it?\n",
        "A:\n",
        "'''\n",
        "\n",
        "# Send the prompt to OpenAI's chat completion API (GPT-3.5 Turbo)\n",
        "response = openai.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": follow_up_prompt}\n",
        "    ],\n",
        "    temperature=0,    # Set temperature to 0 for deterministic and precise answers\n",
        "    max_tokens=512    # Limit response length to 512 tokens\n",
        ")\n",
        "\n",
        "# Print the model's reply\n",
        "print(response.choices[0].message.content)\n"
      ],
      "metadata": {
        "id": "sPNYY1OZcu51"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}